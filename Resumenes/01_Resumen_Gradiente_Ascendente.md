# ðŸ“˜ Entendiendo el Gradiente Ascendente en RegresiÃ³n LogÃ­stica

Este resumen explica en lenguaje natural dos implementaciones del algoritmo de **gradiente ascendente** para regresiÃ³n logÃ­stica:  
una usando **vectores (NumPy)** y otra con **bucles explÃ­citos (sin vectores)**.  
EstÃ¡ diseÃ±ado para que puedas estudiarlo, explicarlo o grabarlo fÃ¡cilmente.

---

## ðŸ§  Â¿QuÃ© es una neurona logÃ­stica?

Una neurona logÃ­stica toma varias entradas \( x_i \), las combina linealmente usando pesos \( w_i \), agrega un sesgo \( b \),  
y aplica la funciÃ³n sigmoide para convertir eso en una **probabilidad**:

$$
z = w_1x_1 + w_2x_2 + \dots + w_nx_n + b, \quad \hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}}
$$

El objetivo es ajustar los pesos \( \beta = [b, w_1, \dots, w_n] \) para que \( \hat{y} \) se aproxime a la etiqueta real \( y \).

---

## ðŸ“— 01 â€“ Gradiente Ascendente **con vectores (NumPy)**

### ðŸ”§ Â¿QuÃ© hace?
Implementa regresiÃ³n logÃ­stica con gradiente ascendente usando Ã¡lgebra lineal (matrices y vectores con NumPy).

### ðŸªœ Pasos clave:

1. **Inicializa \( \beta \) en ceros.**
2. **Agrega columna de unos a \( X \)** para representar el sesgo.
3. En cada iteraciÃ³n:
   - Calcula \( \hat{y} = \sigma(X \cdot \beta) \)
   - Calcula el gradiente:  
     $$ \nabla = X^T \cdot (Y - \hat{y}) $$
   - EvalÃºa la norma del gradiente para saber si hay que seguir.
   - Actualiza los pesos:
     $$ \beta := \beta + \eta \cdot \nabla $$

### ðŸ’¬ Â¿CÃ³mo explicarlo?
> El modelo predice con una combinaciÃ³n lineal y la sigmoide.  
> Compara esa predicciÃ³n con el valor real.  
> El gradiente le dice hacia dÃ³nde ajustar los pesos para mejorar.  
> Y la actualizaciÃ³n da un paso en esa direcciÃ³n. Repite hasta que converge.

---

## ðŸ“™ 02 â€“ Gradiente Ascendente **sin vectores (con bucles)**

### ðŸ”§ Â¿QuÃ© hace?
Implementa lo mismo, pero **paso a paso** usando listas y ciclos for para entender mejor el funcionamiento interno.

### ðŸªœ Componentes clave:

- `calcular_probabilidades`: evalÃºa la sigmoide manualmente.
- `calcular_gradiente`: acumula los errores manualmente para cada peso.
- `norma_vector`: mide la magnitud del gradiente.
- `actualizar_beta`: aplica la fÃ³rmula de actualizaciÃ³n a mano.

### ðŸ’¬ Â¿CÃ³mo explicarlo?
> AquÃ­ hacemos todo sin librerÃ­as mÃ¡gicas: sumamos, multiplicamos y derivamos manualmente.  
> Eso nos obliga a ver cÃ³mo cada error se propaga y ajusta los pesos.  
> Es mÃ¡s lento, pero excelente para aprender desde cero cÃ³mo aprende un modelo.

---

## ðŸ” Â¿QuÃ© comparten ambos?

| Etapa | PropÃ³sito |
|-------|-----------|
| PredicciÃ³n \( \hat{y} = \sigma(X \cdot \beta) \) | Obtener probabilidad de clase positiva |
| Error \( Y - \hat{y} \) | Comparar con etiquetas reales |
| Gradiente \( \nabla = X^T (Y - \hat{y}) \) | Saber en quÃ© direcciÃ³n mejorar |
| ActualizaciÃ³n \( \beta = \beta + \eta \cdot \nabla \) | Ajustar los pesos |

---

## âœ… ConclusiÃ³n

Ambos programas muestran cÃ³mo una neurona logÃ­stica puede **aprender por sÃ­ sola** a separar clases ajustando sus pesos.  
Ya sea con NumPy o con bucles, el corazÃ³n del algoritmo es el mismo:

> Predecir â†’ Comparar â†’ Calcular error â†’ Derivar â†’ Actualizar.

Ese ciclo es el alma del **gradiente ascendente** ðŸ’¡
