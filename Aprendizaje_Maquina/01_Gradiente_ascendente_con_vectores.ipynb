{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üßÆ Gradiente Ascendente con Vectores\n",
        "\n",
        "En este notebook vamos a implementar **el algoritmo de Gradiente Ascendente** aplicado a la **regresi√≥n log√≠stica**.  \n",
        "La idea es aprender a *maximizar* la **verosimilitud** del modelo ajustando los par√°metros (pesos) del vector Œ≤.\n",
        "\n",
        "Aprenderemos:\n",
        "- Qu√© son los vectores y matrices en NumPy.\n",
        "- C√≥mo se calcula el **producto punto**.\n",
        "- Qu√© hace la **funci√≥n sigmoide**.\n",
        "- C√≥mo funciona el **gradiente ascendente** paso a paso.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## üìå Conceptos Clave\n",
        "\n",
        "### üîπ Vectores\n",
        "Un **vector** es una lista ordenada de n√∫meros, por ejemplo:  \n",
        "\\[\n",
        "v = [1, 2, 3]\n",
        "\\]  \n",
        "Los usamos para representar **caracter√≠sticas (features)** de una observaci√≥n.\n",
        "\n",
        "- **Producto punto (`np.dot`)**:  \n",
        "  Multiplica elemento a elemento y suma los resultados.  \n",
        "  Ejemplo:  \n",
        "  \\[\n",
        "  [1,2,3] \\cdot [1,0,1] = 1*1 + 2*0 + 3*1 = 4\n",
        "  \\]\n",
        "  Se usa much√≠simo en modelos lineales y redes neuronales.\n",
        "\n",
        "- **Producto cruz (`np.cross`)**:  \n",
        "  Aplica en vectores 3D y devuelve un vector **perpendicular** a ambos.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Matrices\n",
        "Una **matriz** es una colecci√≥n bidimensional de n√∫meros (filas √ó columnas).  \n",
        "Ejemplo:\n",
        "\\[\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6\n",
        "\\end{bmatrix}\n",
        "\\]\n",
        "- `np.array([[1,2,3],[4,5,6]])` crea una matriz.  \n",
        "- El atributo `.shape` te dice su tama√±o `(renglones, columnas)`.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Operaciones importantes\n",
        "\n",
        "| Operaci√≥n | C√≥digo | Descripci√≥n |\n",
        "|------------|--------|-------------|\n",
        "| **Multiplicaci√≥n matricial** | `A @ B` | Multiplica matrices (n√óm)*(m√ók) = (n√ók) |\n",
        "| **Transpuesta** | `A.T` | Invierte renglones y columnas |\n",
        "| **Matriz de ceros** | `np.zeros((n,m))` | Llena con 0.0 |\n",
        "| **Matriz de unos** | `np.ones((n,m))` | Llena con 1.0 |\n",
        "| **Forma** | `A.shape` | Devuelve tama√±o (renglones, columnas) |\n",
        "| **Reshape** | `A.reshape((n,m))` | Cambia la forma de un arreglo |\n",
        "| **Stack horizontal** | `np.hstack((A,B))` | Une matrices por columnas |\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfyjxDmrv35N",
        "outputId": "e05df4cf-8ab2-425c-c699-4d188505686c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector 1: [1 2 3]\n",
            "Vector 2: [1 0 1]\n",
            "Producto punto: 4\n",
            "Producto cruz: [ 2  2 -2]\n",
            "Matriz 1:\n",
            "[[1 2 3 0]\n",
            " [4 5 6 1]\n",
            " [7 8 9 8]]\n",
            "\n",
            "Matriz 2:\n",
            "[[ 1  2  3]\n",
            " [ 4  5  6]\n",
            " [ 7  8  9]\n",
            " [10 11 12]]\n",
            "\n",
            "Matriz multiplicada m3:\n",
            "[[ 30  36  42]\n",
            " [ 76  92 108]\n",
            " [182 214 246]]\n",
            "\n",
            "Transpuesta de m3:\n",
            "[[ 30  76 182]\n",
            " [ 36  92 214]\n",
            " [ 42 108 246]]\n",
            "\n",
            "Matriz m4 (ceros):\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n",
            "\n",
            "Matriz m5 (unos):\n",
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]]\n",
            "\n",
            "Forma de m5: (3, 2)\n",
            "Renglones: 3\n",
            "Columnas: 2\n",
            "\n",
            "Desempaquetamiento de tupla .shape:\n",
            "Renglones: 3\n",
            "Columnas: 2\n",
            "\n",
            "Vector columna (4x1):\n",
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "\n",
            "Despu√©s del reshape (1x4):\n",
            "[[1. 1. 1. 1.]]\n",
            "Matriz original m6:\n",
            "[[1 2]\n",
            " [3 4]]\n",
            "\n",
            "Matriz resultante de m6 despu√©s del hstack (columna de unos agregada):\n",
            "[[1. 1. 2.]\n",
            " [1. 3. 4.]]\n"
          ]
        }
      ],
      "source": [
        "# importamos la libreria numpy\n",
        "import numpy as np # Para hacer calculos num√©ricos\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# üìå 1. VECTORES\n",
        "# ------------------------------------------------------\n",
        "\n",
        "# definimos vectores (arreglos 1D)\n",
        "v1 = np.array([1,2,3])\n",
        "v2 = np.array([1,0,1])\n",
        "print(\"Vector 1:\", v1)\n",
        "print(\"Vector 2:\", v2)\n",
        "\n",
        "# Producto punto (dot product)\n",
        "# Multiplica elemento a elemento y luego suma los resultados:\n",
        "#  (1*1) + (2*0) + (3*1) = 4\n",
        "a = np.dot(v1,v2)\n",
        "print(\"Producto punto:\", a)\n",
        "\n",
        "# Producto cruz (cross product)\n",
        "# Devuelve un nuevo vector perpendicular a los dos vectores de entrada\n",
        "b = np.cross(v1,v2)\n",
        "print(\"Producto cruz:\", b)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# üìå 2. MATRICES\n",
        "# ------------------------------------------------------\n",
        "\n",
        "# Creamos una matriz 3x4 (3 renglones, 4 columnas)\n",
        "m1 = np.array([\n",
        "      [1,2,3,0],\n",
        "      [4,5,6,1],\n",
        "      [7,8,9,8]\n",
        "])\n",
        "\n",
        "# Creamos una matriz 4x3\n",
        "m2 = np.array([\n",
        "      [1,2,3],\n",
        "      [4,5,6],\n",
        "      [7,8,9],\n",
        "      [10,11,12]\n",
        "])\n",
        "\n",
        "print(\"Matriz 1:\")\n",
        "print(m1)\n",
        "print(\"\\nMatriz 2:\")\n",
        "print(m2)\n",
        "\n",
        "# Multiplicamos matrices\n",
        "# Regla: (n√óm) * (m√ók) = (n√ók)\n",
        "# Aqu√≠: (3x4) * (4x3) = (3x3)\n",
        "m3 = m1 @ m2 # @ es un operador de numpy para mult de matrices\n",
        "print(\"\\nMatriz multiplicada m3:\")\n",
        "print(m3)\n",
        "\n",
        "# La transpuesta invierte renglones por columnas\n",
        "m3t = m3.T\n",
        "print(\"\\nTranspuesta de m3:\")\n",
        "print(m3t)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# üìå 5. MATRICES DE CEROS Y UNOS\n",
        "# ------------------------------------------------------\n",
        "\n",
        "# Matriz de ceros: llena con 0.0\n",
        "m4 = np.zeros((3, 5))  # 3 renglones, 5 columnas\n",
        "print(\"\\nMatriz m4 (ceros):\")\n",
        "print(m4)\n",
        "\n",
        "# creamos matriz de unos\n",
        "# Matriz de unos: llena con 1.0\n",
        "m5 = np.ones((3, 2))   # 3 renglones, 2 columnas\n",
        "print(\"\\nMatriz m5 (unos):\")\n",
        "print(m5)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# üìå 6. OBTENER DIMENSIONES DE UNA MATRIZ\n",
        "# ------------------------------------------------------\n",
        "\n",
        "# La propiedad .shape devuelve una tupla (renglones, columnas)\n",
        "print(\"\\nForma de m5:\", m5.shape) # (3, 2)\n",
        "\n",
        "# Guardamos los valores de renglones y columnas\n",
        "r = m5.shape[0]  # n√∫mero de renglones\n",
        "c = m5.shape[1]  # n√∫mero de columnas\n",
        "print(\"Renglones:\", r)\n",
        "print(\"Columnas:\", c)\n",
        "\n",
        "# Tambi√©n se puede \"desempaquetar\" directamente\n",
        "r, c = m5.shape\n",
        "print(\"\\nDesempaquetamiento de tupla .shape:\")\n",
        "print(\"Renglones:\", r)\n",
        "print(\"Columnas:\", c)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# üìå 7. REFORMA (RESHAPE) DE MATRICES Y VECTORES\n",
        "# ------------------------------------------------------\n",
        "\n",
        "# Podemos cambiar la forma de un vector\n",
        "\n",
        "# Creamos un vector columna de 4x1 con unos\n",
        "v4 = np.ones((4,1)) # vector columna (4 renglones, 1 columna)\n",
        "print(\"\\nVector columna (4x1):\")\n",
        "print(v4)\n",
        "\n",
        "# Cambiamos su forma a vector fila (1x4)\n",
        "v5 = v4.reshape((1, 4))\n",
        "print(\"\\nDespu√©s del reshape (1x4):\")\n",
        "print(v5)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# üìå 8. APILAMIENTO DE MATRICES (STACK)\n",
        "# ------------------------------------------------------\n",
        "\n",
        "# Creamos una matriz base 2x2\n",
        "m6 = np.array([\n",
        "    [1, 2],\n",
        "    [3, 4]\n",
        "])\n",
        "\n",
        "# Agregamos una columna de unos al inicio\n",
        "# np.hstack concatena matrices horizontalmente\n",
        "print(\"Matriz original m6:\")\n",
        "print(m6)\n",
        "m7 = np.hstack((np.ones((2, 1)), m6))\n",
        "print(\"\\nMatriz resultante de m6 despu√©s del hstack (columna de unos agregada):\")\n",
        "print(m7)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJKZSQe6-lHd"
      },
      "source": [
        "# üß† Funci√≥n Sigmoide y Algoritmo de Gradiente Ascendente\n",
        "\n",
        "En esta secci√≥n implementamos dos piezas fundamentales de la **regresi√≥n log√≠stica**:\n",
        "\n",
        "1. **Funci√≥n sigmoide (œÉ)**  \n",
        "   Convierte cualquier n√∫mero real en un valor entre 0 y 1, lo que nos permite\n",
        "   interpretar las salidas del modelo como **probabilidades**.\n",
        "\n",
        "2. **Algoritmo de gradiente ascendente**  \n",
        "   Ajusta los par√°metros del modelo (Œ≤) de forma iterativa, buscando los valores\n",
        "   que **maximizan la verosimilitud** ‚Äî es decir, los que hacen que las predicciones\n",
        "   del modelo se parezcan lo m√°s posible a los datos reales.\n",
        "\n",
        "üîç En t√©rminos pr√°cticos:\n",
        "- La sigmoide act√∫a como la ‚Äúpuerta‚Äù que transforma valores continuos en decisiones probabil√≠sticas.\n",
        "- El gradiente ascendente es el **motor de aprendizaje** que optimiza esos valores.\n",
        "\n",
        "üì¶ Estos dos componentes son la base no solo de la regresi√≥n log√≠stica,\n",
        "sino tambi√©n de redes neuronales y muchos algoritmos de clasificaci√≥n modernos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59g-TcNC-o9u",
        "outputId": "d434ba43-c011-498a-b8af-f109871a7c7a"
      },
      "outputs": [],
      "source": [
        "# ======================================================\n",
        "# üß† FUNCI√ìN SIGMOIDE Y GRADIENTE ASCENDENTE\n",
        "# ======================================================\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# üìå 1. FUNCI√ìN SIGMOIDE\n",
        "# ------------------------------------------------------\n",
        "def sigmoide(z):\n",
        "    \"\"\"\n",
        "    Funci√≥n de activaci√≥n sigmoide:\n",
        "    œÉ(z) = 1 / (1 + e^(-z))\n",
        "\n",
        "    Convierte cualquier n√∫mero real (positivo o negativo)\n",
        "    en un valor dentro del rango (0, 1).\n",
        "\n",
        "    En regresi√≥n log√≠stica, esta salida se interpreta como una probabilidad:\n",
        "    - Valores cercanos a 1 ‚Üí alta probabilidad de que Y sea 1 (clase positiva).\n",
        "    - Valores cercanos a 0 ‚Üí alta probabilidad de que Y sea 0 (clase negativa).\n",
        "    - Valores alrededor de 0.5 ‚Üí el modelo est√° indeciso.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# üìå 2. FUNCI√ìN DE GRADIENTE ASCENDENTE\n",
        "# ------------------------------------------------------\n",
        "def grad_asc(Xc, Y, eta=0.1, max_it=10000):\n",
        "    \"\"\"\n",
        "    Entrena un modelo de regresi√≥n log√≠stica usando **gradiente ascendente**.\n",
        "\n",
        "    üí° Idea general:\n",
        "    ----------------\n",
        "    Ajusta los par√°metros Œ≤ para que las predicciones del modelo\n",
        "    se acerquen lo m√°s posible a los valores reales observados en Y.\n",
        "\n",
        "    üîç En otras palabras:\n",
        "    El algoritmo busca los Œ≤ que maximizan la probabilidad (verosimilitud)\n",
        "    de que el modelo haya generado los datos que tenemos.\n",
        "\n",
        "    üîÅ Retorna:\n",
        "    -----------\n",
        "    beta : np.ndarray (n+1, 1)\n",
        "        Vector de pesos aprendidos (incluye el sesgo Œ≤‚ÇÄ).\n",
        "    \"\"\"\n",
        "\n",
        "    # m = n√∫mero de ejemplos (filas), n = n√∫mero de caracter√≠sticas (columnas)\n",
        "    m, n = Xc.shape # obtenemos dimensiones de Xc\n",
        "\n",
        "    # Inicializamos los pesos en cero (Œ≤‚ÇÄ + Œ≤‚ÇÅ ... Œ≤n)\n",
        "    beta = np.zeros((n + 1, 1)) \n",
        "\n",
        "    # Agregamos una columna de unos al inicio ‚Üí representa el sesgo Œ≤‚ÇÄ\n",
        "    X = np.hstack((np.ones((m, 1)), Xc))\n",
        "\n",
        "    # --------------------------------------------------\n",
        "    # üîÅ Bucle de entrenamiento\n",
        "    # --------------------------------------------------\n",
        "    for i in range(max_it):\n",
        "\n",
        "        # 1Ô∏è‚É£ Predicci√≥n del modelo: œÉ(X¬∑Œ≤)\n",
        "        # La sigmoide transforma la combinaci√≥n lineal X¬∑Œ≤ en probabilidades (0 a 1)\n",
        "        p = sigmoide(X @ beta) \n",
        "        #X: matriz de caracter√≠sticas con columna de unos\n",
        "        #beta: vector de pesos\n",
        "\n",
        "        # 2Ô∏è‚É£ C√°lculo del gradiente:\n",
        "        # (Y - p) mide el error entre lo real y lo predicho.\n",
        "        # X.T @ (Y - p) indica hacia d√≥nde mover los Œ≤ para mejorar las predicciones.\n",
        "        grad = X.T @ (Y - p)\n",
        "        #X.T: transpuesta de la matriz de caracter√≠sticas\n",
        "        #Y: etiquetas reales\n",
        "        #p: probabilidades predichas por el modelo\n",
        "        \n",
        "\n",
        "        # 3Ô∏è‚É£ Evaluar el tama√±o del cambio\n",
        "        # Si el gradiente es casi 0, significa que ya llegamos al ‚Äúpunto √≥ptimo‚Äù.\n",
        "        norm_grad = np.linalg.norm(grad)\n",
        "\n",
        "        if norm_grad < 1e-4:\n",
        "            print(f\"‚úÖ Convergencia alcanzada en la iteraci√≥n {i}\")\n",
        "            break\n",
        "\n",
        "        # 4Ô∏è‚É£ Actualizamos los par√°metros (subimos por la \"monta√±a\" de verosimilitud)\n",
        "        #   beta ‚Üê beta + Œ∑ * grad\n",
        "        # eta controla el tama√±o del paso (tasa de aprendizaje)\n",
        "        beta = beta + eta * grad\n",
        "\n",
        "    # Retorna los Œ≤ finales: los valores que mejor ajustan el modelo\n",
        "    return beta\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß™ Ejemplo pr√°ctico: entrenamiento del modelo\n",
        "\n",
        "En este ejemplo creamos un conjunto de datos muy simple para probar el algoritmo:\n",
        "\n",
        "- **Xc** representa las caracter√≠sticas de entrada (cada fila es un ejemplo y cada columna una variable).  \n",
        "- **Y** son las *etiquetas reales*, es decir, los valores correctos que el modelo debe aprender a predecir (0 o 1).  \n",
        "- Luego entrenamos el modelo con `grad_asc()`, que ajusta los pesos **Œ≤** para que las predicciones se acerquen lo m√°s posible a los valores reales.\n",
        "\n",
        "Al final se imprimen los par√°metros aprendidos:\n",
        "- **Œ≤‚ÇÄ** es el sesgo o intercepto.  \n",
        "- **Œ≤‚ÇÅ, Œ≤‚ÇÇ, ...** son los pesos de cada caracter√≠stica, indicando su influencia en la probabilidad de que la salida sea 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Par√°metros Œ≤ aprendidos:\n",
            "[[ 6.90214847e+00]\n",
            " [-6.90214847e+00]\n",
            " [-6.90214847e+00]\n",
            " [-3.91173639e-15]\n",
            " [-3.91173639e-15]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Cada fila representa un ejemplo y cada columna una caracter√≠stica (feature)\n",
        "Xc = np.array([\n",
        "    [0, 0, 1, 0],\n",
        "    [1, 1, 1, 1],\n",
        "    [0, 0, 0, 1]\n",
        "])\n",
        "\n",
        "# Etiquetas reales (valores correctos que el modelo debe aprender a predecir)\n",
        "# 1 = clase positiva, 0 = clase negativa\n",
        "Y = np.array([1, 0, 1]).reshape((-1, 1))\n",
        "\n",
        "# Entrenamiento del modelo: ajusta los pesos Œ≤ para que las predicciones\n",
        "# se acerquen lo m√°s posible a las etiquetas reales (Y)\n",
        "betas = grad_asc(Xc, Y)\n",
        "\n",
        "# Œ≤‚ÇÄ es el sesgo (intercepto) y los dem√°s Œ≤ son los pesos de cada caracter√≠stica\n",
        "print(\"\\nPar√°metros Œ≤ aprendidos:\")\n",
        "print(betas)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
