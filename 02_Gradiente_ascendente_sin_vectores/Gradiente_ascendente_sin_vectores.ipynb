{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759986de",
   "metadata": {},
   "source": [
    "# Gradiente ascendente sin vectores\n",
    "\n",
    "Este notebook implementa el gradiente ascendente usando ciclos y operaciones elemento a elemento. El objetivo es entender cómo se construye el gradiente y cómo se actualizan los parámetros del modelo de forma explícita."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf819ebb",
   "metadata": {},
   "source": [
    "## Imports y datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66ab27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Ejemplo de conjunto de datos pequeño\n",
    "# Cada fila de X representa un ejemplo y cada columna una característica (feature)\n",
    "X = np.array([\n",
    "    [0, 0, 1, 0],\n",
    "    [1, 1, 1, 1],\n",
    "    [0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "# Etiquetas reales (Y[i] = 1 para clase positiva, 0 para clase negativa)\n",
    "Y = np.array([1, 0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a642b8",
   "metadata": {},
   "source": [
    "## Función sigmoide\n",
    "\n",
    "Definimos la función sigmoide como función de activación. \n",
    "Toma un valor escalar y regresa un valor entre 0 y 1, interpretado como probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f3d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Calcula la función sigmoide para un valor escalar z.\n",
    "\n",
    "    Parámetros:\n",
    "        z: número real (float)\n",
    "\n",
    "    Regresa:\n",
    "        float en el intervalo (0, 1)\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111e2621",
   "metadata": {},
   "source": [
    "## Cálculo de probabilidades\n",
    "\n",
    "Calcula, para cada ejemplo, la probabilidad de que Y = 1 dada la combinación lineal de características.  \n",
    "Se usa la función sigmoide aplicada a la suma ponderada de entradas y parámetros (β)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a3b57d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_probabilidades(X, beta):\n",
    "    \"\"\"\n",
    "    Calcula las probabilidades predichas para cada ejemplo.\n",
    "\n",
    "    Fórmula:\n",
    "        p[i] = P(Y[i]=1 | X[i]) = sigmoid(sum_j beta[j] * X[i][j])\n",
    "\n",
    "    Parámetros:\n",
    "        X     : matriz de características (m x n)\n",
    "        beta  : lista o vector con los parámetros actuales del modelo (longitud n)\n",
    "\n",
    "    Regresa:\n",
    "        Lista con las probabilidades p[i] para cada ejemplo\n",
    "    \"\"\"\n",
    "    m = len(X)\n",
    "    n = len(beta)\n",
    "\n",
    "    # Inicializar lista de probabilidades con ceros\n",
    "    p = [0.0 for _ in range(m)]\n",
    "\n",
    "    # Calcular z = β·x para cada ejemplo y aplicar la sigmoide\n",
    "    for i in range(m):\n",
    "        z = 0.0\n",
    "        for j in range(n):\n",
    "            z += beta[j] * X[i][j]\n",
    "        p[i] = sigmoid(z)\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd69613",
   "metadata": {},
   "source": [
    "## Cálculo del gradiente\n",
    "\n",
    "El gradiente se obtiene sumando la contribución de cada ejemplo.  \n",
    "Para cada parámetro β_j, se acumula la cantidad `(Y[i] - p[i]) * X[i][j]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13370da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_gradiente(X, Y, p):\n",
    "    \"\"\"\n",
    "    Calcula el gradiente de la función de verosimilitud.\n",
    "\n",
    "    Fórmula:\n",
    "        grad[j] = sum_i (Y[i] - p[i]) * X[i][j]\n",
    "\n",
    "    Parámetros:\n",
    "        X : matriz de características (m x n)\n",
    "        Y : vector de etiquetas reales\n",
    "        p : lista de probabilidades predichas\n",
    "\n",
    "    Regresa:\n",
    "        grad : lista con la derivada parcial de cada parámetro β_j\n",
    "    \"\"\"\n",
    "    n = len(X[0])\n",
    "    m = len(X)\n",
    "\n",
    "    grad = [0.0 for _ in range(n)]\n",
    "\n",
    "    # Para cada parámetro beta_j\n",
    "    for j in range(n):\n",
    "        suma = 0.0\n",
    "        # Sumar las contribuciones de cada ejemplo\n",
    "        for i in range(m):\n",
    "            suma += (Y[i] - p[i]) * X[i][j]\n",
    "        grad[j] = suma\n",
    "\n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f7513f",
   "metadata": {},
   "source": [
    "## Norma Euclidiana del gradiente\n",
    "\n",
    "Se usa para medir el tamaño del vector gradiente.  \n",
    "Permite definir una condición de paro cuando el gradiente es suficientemente pequeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c58768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norma_vector(v):\n",
    "    \"\"\"\n",
    "    Calcula la norma Euclidiana de un vector.\n",
    "\n",
    "    Fórmula:\n",
    "        ||v||_2 = sqrt(sum_j v[j]^2)\n",
    "\n",
    "    Parámetros:\n",
    "        v : lista o vector numérico\n",
    "\n",
    "    Regresa:\n",
    "        Valor escalar con la norma Euclidiana de v\n",
    "    \"\"\"\n",
    "    suma = 0.0\n",
    "    for i in range(len(v)):\n",
    "        suma += v[i] * v[i]\n",
    "    return math.sqrt(suma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed838794",
   "metadata": {},
   "source": [
    "## Actualización de parámetros β\n",
    "\n",
    "Se actualiza cada parámetro en dirección del gradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d812f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def actualizar_beta(beta, grad, eta):\n",
    "    \"\"\"\n",
    "    Actualiza los parámetros beta usando la regla del gradiente ascendente.\n",
    "\n",
    "    Fórmula:\n",
    "        beta_j^{nuevo} = beta_j^{viejo} + eta * grad[j]\n",
    "\n",
    "    Parámetros:\n",
    "        beta : lista de parámetros actuales\n",
    "        grad : gradiente calculado\n",
    "        eta  : tasa de aprendizaje\n",
    "\n",
    "    Regresa:\n",
    "        Lista beta actualizada\n",
    "    \"\"\"\n",
    "    n = len(beta)\n",
    "    for j in range(n):\n",
    "        beta[j] += eta * grad[j]\n",
    "    return beta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4dc9ad",
   "metadata": {},
   "source": [
    "## Algoritmo completo de gradiente ascendente\n",
    "\n",
    "Integra todas las funciones anteriores:\n",
    "1. Calcula probabilidades.\n",
    "2. Calcula gradiente.\n",
    "3. Evalúa la norma del gradiente.\n",
    "4. Actualiza parámetros hasta converger o alcanzar el máximo de iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57c0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradiente_ascendente(X, Y, eta=0.01, max_iter=1000, tol=0.0001):\n",
    "    \"\"\"\n",
    "    Implementa el algoritmo completo de gradiente ascendente.\n",
    "\n",
    "    Parámetros:\n",
    "        X         : matriz de características (m x n)\n",
    "        Y         : vector de etiquetas (longitud m)\n",
    "        eta       : tasa de aprendizaje\n",
    "        max_iter  : número máximo de iteraciones\n",
    "        tol       : tolerancia para detener cuando ||grad|| < tol\n",
    "\n",
    "    Regresa:\n",
    "        beta : lista con los parámetros ajustados\n",
    "    \"\"\"\n",
    "    n = len(X[0])\n",
    "    beta = [0.0 for _ in range(n)]  # inicialización de parámetros\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        # 1. Calcular probabilidades\n",
    "        p = calcular_probabilidades(X, beta)\n",
    "\n",
    "        # 2. Calcular gradiente\n",
    "        grad = calcular_gradiente(X, Y, p)\n",
    "\n",
    "        # 3. Calcular norma del gradiente\n",
    "        grad_norm = norma_vector(grad)\n",
    "\n",
    "        if grad_norm < tol:\n",
    "            print(f\"Convergió en {iteration} iteraciones\")\n",
    "            break\n",
    "\n",
    "        # 4. Actualizar parámetros\n",
    "        beta = actualizar_beta(beta, grad, eta)\n",
    "\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6fa9e",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo y resultado final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4abc2039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros finales aprendidos (beta):\n",
      "[np.float64(-4.607455855430737), np.float64(-4.607455855430737), np.float64(2.892886219289177), np.float64(2.892886219289177)]\n"
     ]
    }
   ],
   "source": [
    "betas_finales = gradiente_ascendente(X, Y, eta=0.01, max_iter=5000, tol=1e-5)\n",
    "\n",
    "print(\"Parámetros finales aprendidos (beta):\")\n",
    "print(betas_finales)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
