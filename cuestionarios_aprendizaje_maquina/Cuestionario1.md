# ğŸ§© Cuestionario 1 de Repaso

### 1ï¸âƒ£ Â¿CuÃ¡ndo es preferible usar el algoritmo del gradiente ascendente en lugar del mÃ©todo directo para obtener el valor de las Î²?

âœ… **Respuesta:**  
Cuando el modelo tiene **funciones trascendentes**, como las exponenciales.

ğŸ’¡ **ExplicaciÃ³n:**  
El mÃ©todo directo no puede resolver funciones con exponentes o sigmoides;  
el gradiente ascendente optimiza iterativamente hasta encontrar el mejor valor.

---

### 2ï¸âƒ£ En un modelo probabilÃ­stico, Â¿cÃ³mo se define la verosimilitud?

âœ… **Respuesta:**  
Es la **funciÃ³n que mide la probabilidad de obtener los datos observados** dado un conjunto de parÃ¡metros del modelo.

ğŸ’¡ **ExplicaciÃ³n:**  
La verosimilitud indica **quÃ© tan probables son los datos** si los parÃ¡metros del modelo son correctos.

---

### 3ï¸âƒ£ Â¿Por quÃ© como condiciÃ³n de paro en el algoritmo del gradiente ascendente se usa que la norma del gradiente tienda a cero?

âœ… **Respuesta:**  
Porque implica que se ha alcanzado un **punto crÃ­tico**.

ğŸ’¡ **ExplicaciÃ³n:**  
Cuando el gradiente se acerca a cero, la funciÃ³n deja de cambiar:  
se ha alcanzado un **mÃ¡ximo o mÃ­nimo**.

---

### 4ï¸âƒ£ Â¿Por quÃ© se aplica logaritmo a la verosimilitud?

âœ… **Respuesta:**  
Porque **permite derivar mÃ¡s fÃ¡cilmente** al aplicar el gradiente ascendente.

ğŸ’¡ **ExplicaciÃ³n:**  
El logaritmo **convierte productos en sumas**, lo que simplifica las derivadas  
y evita errores numÃ©ricos por nÃºmeros demasiado pequeÃ±os.

---

### 5ï¸âƒ£ Â¿QuÃ© sucede si el valor de Î· (tasa de aprendizaje) es demasiado grande?

âœ… **Respuesta:**  
El algoritmo puede **oscilar sin converger** a una soluciÃ³n.

ğŸ’¡ **ExplicaciÃ³n:**  
Una tasa de aprendizaje muy alta hace que los pasos sean demasiado grandes,  
haciendo que el algoritmo â€œreboteâ€ y no alcance el mÃ¡ximo.

---

### 6ï¸âƒ£ Â¿CuÃ¡l es el resultado de `np.hstack([a,b])` con `a=[[1],[2]]` y `b=[[3],[4]]`?

âœ… **Respuesta:**  
`[[1, 3], [2, 4]]`

ğŸ’¡ **ExplicaciÃ³n:**  
`np.hstack()` concatena **por columnas**,  
formando una matriz de **2Ã—2** al unir los vectores verticalmente.

---

### 7ï¸âƒ£ En el algoritmo de mÃ¡xima verosimilitud, Â¿quÃ© se asume sobre los vectores aleatorios X^(i)?

âœ… **Respuesta:**  
Que son **condicionalmente independientes**.

ğŸ’¡ **ExplicaciÃ³n:**  
Cada muestra depende Ãºnicamente de su propio **X^(i)** y de los parÃ¡metros del modelo,  
no de otras muestras.

---

### 8ï¸âƒ£ Â¿CuÃ¡l de los siguientes programas multiplica correctamente el producto punto entre dos arreglos NumPy `a` y `b`?

âœ… **Respuesta:**  
`a.dot(b)`

ğŸ’¡ **ExplicaciÃ³n:**  
`a.dot(b)` o `np.dot(a,b)` calculan el **producto punto**,  
es decir, multiplican y suman los elementos correspondientes.

---

### 9ï¸âƒ£ Â¿Por quÃ© se usa el modelo de regresiÃ³n logÃ­stica en lugar de una distribuciÃ³n de probabilidad conjunta discreta?

âœ… **Respuesta:**  
Porque **guardar la distribuciÃ³n completa es intratable** en tÃ©rminos de memoria.

ğŸ’¡ **ExplicaciÃ³n:**  
Una distribuciÃ³n conjunta requiere almacenar **2â¿ combinaciones**,  
lo cual es imposible para valores grandes de *n*;  
la regresiÃ³n logÃ­stica es **mÃ¡s eficiente y prÃ¡ctica**.

---

