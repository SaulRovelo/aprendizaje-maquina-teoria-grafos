{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejemplo de uso de Red Neuronal para reconocer imágenes\n",
        "\n",
        "En este cuaderno implementaremos una **red neuronal simple con PyTorch** para **reconocer dígitos escritos a mano (0 y 1)** del conjunto **MNIST**.  \n",
        "\n",
        "El objetivo es comprender paso a paso cómo:\n",
        "- Se **preparan los datos** (transformaciones, lotes y etiquetas),\n",
        "- Se **define un modelo neuronal** (capas, función de activación y salida),\n",
        "- Se **entrena y evalúa** mediante una función de pérdida y optimizador.\n",
        "\n",
        "Este ejemplo aplica los conceptos teóricos de **regresión logística**, **función sigmoide** y **gradiente ascendente**, extendiéndolos al caso de una **red neuronal multicapa** que aprende a clasificar imágenes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0YulYj0HNW2"
      },
      "source": [
        "### Importamos librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zj6Av5iHSUV"
      },
      "outputs": [],
      "source": [
        "import torch                         # Manejo de tensores y operaciones con GPU\n",
        "import torch.nn as nn                # Módulo para definir redes neuronales\n",
        "import torch.optim as optim          # Métodos de optimización (SGD, Adam, etc.)\n",
        "from torchvision import datasets, transforms  # Conjuntos de datos y transformaciones\n",
        "from torch.utils.data import DataLoader       # Carga de datos por lotes (batch)\n",
        "import matplotlib.pyplot as plt      # Para graficar imágenes y resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fljayq0bKtP7"
      },
      "source": [
        "### Inicialización de datos de entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOM8_Ym9J-JV"
      },
      "outputs": [],
      "source": [
        "# Inicialización de los datos (entrenamiento y prueba)\n",
        "\n",
        "# transforms.ToTensor()\n",
        "# Convierte imágenes en tensores de PyTorch.\n",
        "# Escala los píxeles de 0–255 a 0.0–1.0 y cambia el formato a (canales, alto, ancho).\n",
        "transformacion = transforms.ToTensor()\n",
        "\n",
        "# datasets.MNIST()\n",
        "# Carga o descarga el conjunto de datos MNIST (dígitos 0–9).\n",
        "# Devuelve pares (imagen, etiqueta).\n",
        "# Argumentos:\n",
        "#   root=\"./data\"          → Carpeta donde se guardan los datos.\n",
        "#   train=True/False       → Define si son datos de entrenamiento o prueba.\n",
        "#   download=True          → Descarga automática si no existen.\n",
        "#   transform=transformacion → Aplica la conversión a tensor.\n",
        "datos_entrenamiento = datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transformacion\n",
        ")\n",
        "\n",
        "datos_prueba = datasets.MNIST(\n",
        "    root=\"./data\", train=False, download=True, transform=transformacion\n",
        ")\n",
        "\n",
        "# Cada elemento del dataset es una tupla (imagen_tensor, etiqueta)\n",
        "# Ejemplo: imagen 28x28 y etiqueta numérica entre 0 y 9.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tOGbWhecGSh"
      },
      "source": [
        "### Máscara de datos para filtrar solo los dígitos 0 y 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfZ3Ec2_cL3c"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Filtrar el dataset para quedarnos solo con los dígitos 0 y 1\n",
        "\n",
        "\n",
        "# Creamos una \"máscara\" booleana para cada conjunto:\n",
        "#   True  → si la etiqueta es 0 o 1\n",
        "#   False → si la etiqueta es otro número (2–9)\n",
        "# Esto nos permite seleccionar solo los ejemplos que pertenecen a las clases deseadas.\n",
        "mascara_entrenamiento = (datos_entrenamiento.targets == 0) | (datos_entrenamiento.targets == 1)\n",
        "mascara_prueba = (datos_prueba.targets == 0) | (datos_prueba.targets == 1)\n",
        "\n",
        "# Usamos las máscaras para filtrar los datos e índices correspondientes:\n",
        "#   - .data almacena las imágenes (matrices 28x28)\n",
        "#   - .targets contiene las etiquetas (número representado)\n",
        "datos_entrenamiento.data = datos_entrenamiento.data[mascara_entrenamiento]\n",
        "datos_entrenamiento.targets = datos_entrenamiento.targets[mascara_entrenamiento]\n",
        "\n",
        "datos_prueba.data = datos_prueba.data[mascara_prueba]\n",
        "datos_prueba.targets = datos_prueba.targets[mascara_prueba]\n",
        "\n",
        "# Ahora ambos conjuntos contienen solo imágenes de los dígitos 0 y 1,\n",
        "# lo que convierte el problema en una clasificación binaria.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9LDj-0gS5KF"
      },
      "source": [
        "### Definimos características X y etiquetas Y (sin aplanar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKPsaPjoS0dL"
      },
      "outputs": [],
      "source": [
        "# Convertimos los datos a tipo flotante para poder operar con PyTorch\n",
        "\n",
        "# .data contiene las imágenes (matrices 28x28)\n",
        "# .float() convierte los valores enteros (0–255) a decimales (0.0–255.0)\n",
        "X_entrenamiento = datos_entrenamiento.data.float()\n",
        "\n",
        "# .targets contiene las etiquetas (0 o 1)\n",
        "# .float() las convierte a tipo flotante, útil para operaciones numéricas posteriores\n",
        "Y_entrenamiento = datos_entrenamiento.targets.float()\n",
        "\n",
        "# .reshape((n,1)) cambia la forma del tensor a una columna\n",
        "# Esto permite que Y tenga dimensión [n,1] en lugar de [n], como exige PyTorch\n",
        "Y_entrenamiento = Y_entrenamiento.reshape((Y_entrenamiento.shape[0], 1))\n",
        "\n",
        "print(\"Ejemplo de etiqueta:\", Y_entrenamiento[0])\n",
        "\n",
        "# Repetimos el mismo proceso para el conjunto de prueba\n",
        "\n",
        "\n",
        "X_prueba = datos_prueba.data.float()\n",
        "Y_prueba = datos_prueba.targets.float()\n",
        "Y_prueba = Y_prueba.reshape((Y_prueba.shape[0], 1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jel0WsM9TVPa"
      },
      "source": [
        "### Definimos modelo, función de pérdida y optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3uaK-MUNJ6n"
      },
      "outputs": [],
      "source": [
        "# Modelo: red totalmente conectada para clasificar 0 vs 1\n",
        "\n",
        "\n",
        "modelo = nn.Sequential(\n",
        "    nn.Flatten(),           # Convierte imagen 1x28x28 → vector 784\n",
        "    nn.Linear(28*28, 512),  # Capa oculta: 784 → 512\n",
        "    nn.Sigmoid(),           # Activación (no linealidad)\n",
        "    nn.Linear(512, 1),      # Capa de salida: 512 → 1 (probabilidad de clase 1)\n",
        "    nn.Sigmoid()            # Mapea salida a [0,1] para clasificación binaria\n",
        ")\n",
        "\n",
        "# Función de pérdida y optimizador\n",
        "\n",
        "fn_perdida = nn.BCELoss()                     # Binary Cross-Entropy para etiquetas {0,1}\n",
        "optimizador = torch.optim.SGD(                 # Descenso por gradiente (SGD)\n",
        "    modelo.parameters(), lr=0.001              # lr: tasa de aprendizaje\n",
        ")\n",
        "\n",
        "# Nota: alternativamente se puede usar nn.BCEWithLogitsLoss()\n",
        "# y quitar la última Sigmoid() para mayor estabilidad numérica.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q-M6y0cTp_e"
      },
      "source": [
        "### Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y8zgiUoTrsP"
      },
      "outputs": [],
      "source": [
        "# Bucle de entrenamiento: el modelo aprende ajustando sus pesos\n",
        "\n",
        "\n",
        "total_iteraciones = 30  # Número de veces que veremos todos los datos (épocas)\n",
        "\n",
        "for i in range(total_iteraciones):\n",
        "\n",
        "    # Forward pass: calculamos las predicciones de la red\n",
        "    y_pred = modelo(X_entrenamiento)\n",
        "\n",
        "    # Cálculo de la pérdida: mide qué tan lejos están las predicciones de las etiquetas reales\n",
        "    perdida = fn_perdida(y_pred, Y_entrenamiento)\n",
        "\n",
        "    # Reinicia los gradientes acumulados del paso anterior\n",
        "    optimizador.zero_grad()\n",
        "\n",
        "    # Backpropagation: calcula los gradientes ∂L/∂w para cada peso del modelo\n",
        "    perdida.backward()\n",
        "\n",
        "    # Actualiza los pesos según el gradiente y la tasa de aprendizaje\n",
        "    optimizador.step()\n",
        "\n",
        "    # Muestra el progreso y el valor actual de la pérdida\n",
        "    print(f\"Iteración {i+1}/{total_iteraciones}, Pérdida: {perdida.item():.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nb6I_JFPTsXz"
      },
      "source": [
        "### Evaluación del modelo en datos de prueba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xo04nXBKTvZC"
      },
      "outputs": [],
      "source": [
        "# Evaluación del modelo: medimos qué tan bien aprendió\n",
        "\n",
        "\n",
        "modelo.eval()  # Cambia el modelo a modo de evaluación (desactiva dropout, batchnorm, etc.)\n",
        "\n",
        "# torch.no_grad() desactiva el cálculo de gradientes para ahorrar memoria y acelerar la inferencia.\n",
        "with torch.no_grad():\n",
        "    # Calculamos las salidas (predicciones continuas entre 0 y 1)\n",
        "    salida = modelo(X_prueba)\n",
        "\n",
        "    # Convertimos las probabilidades en etiquetas binarias:\n",
        "    #   > 0.5 → clase 1,  ≤ 0.5 → clase 0\n",
        "    predicciones = (salida > 0.5).float()\n",
        "\n",
        "    # Comparamos predicciones con etiquetas verdaderas\n",
        "    # .sum() cuenta cuántas predicciones son correctas\n",
        "    # .item() convierte el resultado tensorial a número normal (Python float)\n",
        "    correctas = (predicciones == Y_prueba).sum().item()\n",
        "\n",
        "    # .size(0) devuelve el total de muestras evaluadas\n",
        "    total = Y_prueba.size(0)\n",
        "\n",
        "# Calculamos el porcentaje de aciertos\n",
        "print(f\"Precisión en prueba: {100 * correctas / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGjfsqIhYb7q"
      },
      "source": [
        "### Pruebas individuales del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PijKAVgNYfQ7"
      },
      "outputs": [],
      "source": [
        "# Prueba individual: verificamos la predicción para una sola imagen\n",
        "\n",
        "\n",
        "# Seleccionamos una imagen del conjunto de prueba\n",
        "indice = 1\n",
        "imagen = X_prueba[indice]      # Tensor de la imagen seleccionada\n",
        "etiqueta = Y_prueba[indice]    # Etiqueta real (0 o 1)\n",
        "\n",
        "\n",
        "# Visualizamos la imagen en escala de grises\n",
        "\n",
        "plt.imshow(imagen.reshape(28, 28), cmap='gray')    # Convertimos a 28x28 para mostrar\n",
        "plt.title(f\"Etiqueta real: {int(etiqueta)}\")       # Mostramos la clase verdadera\n",
        "plt.show()\n",
        "# Evaluamos el modelo con esa imagen\n",
        "modelo.eval()  # Modo evaluación (sin actualización de pesos)\n",
        "\n",
        "with torch.no_grad():  # Sin cálculo de gradientes (ahorra memoria)\n",
        "    entrada = imagen.reshape(1, 28, 28)    # Redimensionamos para simular un lote (batch=1)\n",
        "    salida = modelo(entrada)               # Forward pass → salida del modelo\n",
        "    prediccion = (salida > 0.5).float()    # Clasificación: 1 si probabilidad > 0.5, de lo contrario 0\n",
        "\n",
        "# Mostramos el resultado del modelo\n",
        "print(f\"Predicción del modelo: {int(prediccion.item())}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
